{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-SF-27 | Codealong 16 | Introduction to Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>> One-time setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import nltk\n",
    "nltk.download()\n",
    "'''\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <<< One-time setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "import string\n",
    "import unicodedata\n",
    "from nltk import tokenize, corpus, stem\n",
    "\n",
    "from sklearn import feature_extraction, linear_model, ensemble, cross_validation, metrics, decomposition\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(document):\n",
    "    document = document.encode('utf-8')\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = tokenize.word_tokenize(document)\n",
    "\n",
    "    # Remove punctuation in tokens and then remove empty tokens\n",
    "    tokens = [token.translate(None, string.punctuation) for token in tokens]\n",
    "    tokens = [token for token in tokens if token]\n",
    "\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if not token in corpus.stopwords.words('english')]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence', 'wait', 'another', 'third']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize_text(\"This is a sentence...  Wait, here's another.  And a third!\")\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Stemmer:\n",
    "    stemmer = stem.porter.PorterStemmer()\n",
    "\n",
    "    @staticmethod\n",
    "    def stem_tokens(tokens):\n",
    "        return [Stemmer.stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sentenc', u'wait', u'anoth', u'third']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = Stemmer.stem_tokens(tokens)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will be analyzing a partial list of the reviews for J.K. Rowling's The Casual Vacancy.  (https://www.amazon.com/dp/0316228532)\n",
    "\n",
    "Our dataset is a subset of http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Books_5.json.gz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('..', 'datasets', 'reviews_Books_5-0316228532.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>summary</th>\n",
       "      <th>review_text</th>\n",
       "      <th>overall</th>\n",
       "      <th>review_time</th>\n",
       "      <th>unix_review_time</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>316228532</td>\n",
       "      <td>AY2UIGHCB4VPB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>but a good read!</td>\n",
       "      <td>A departure for her, but a good read!</td>\n",
       "      <td>5</td>\n",
       "      <td>07 12, 2014</td>\n",
       "      <td>1405123200</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A2L17U0TWH9UWS</td>\n",
       "      <td>1075</td>\n",
       "      <td>Not worth the time</td>\n",
       "      <td>I had a hard time remembering who each charact...</td>\n",
       "      <td>2</td>\n",
       "      <td>11 12, 2013</td>\n",
       "      <td>1384214400</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A2R63TBVG5OAF6</td>\n",
       "      <td>12121</td>\n",
       "      <td>The Casual Vacancy</td>\n",
       "      <td>This is the only review I have ever written.  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>10 1, 2012</td>\n",
       "      <td>1349049600</td>\n",
       "      <td>[13, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316228532</td>\n",
       "      <td>ACU39L9G696US</td>\n",
       "      <td>123esmo</td>\n",
       "      <td>Expecting more from J.K. Rowling</td>\n",
       "      <td>I was expecting more from J.K. Rowling, it's a...</td>\n",
       "      <td>2</td>\n",
       "      <td>01 10, 2013</td>\n",
       "      <td>1357776000</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A3N7KY1PBMF880</td>\n",
       "      <td>&amp;#34;Bad Cat!&amp;#34;</td>\n",
       "      <td>Sorry That I  Bought It.</td>\n",
       "      <td>As big a fan as I am of J K Rowling's Harry Po...</td>\n",
       "      <td>1</td>\n",
       "      <td>05 11, 2013</td>\n",
       "      <td>1368230400</td>\n",
       "      <td>[0, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A1SCYWLS37YR50</td>\n",
       "      <td>ZC</td>\n",
       "      <td>Spectacular prose in a rambling story</td>\n",
       "      <td>Spectacular prose in a rambling story that see...</td>\n",
       "      <td>5</td>\n",
       "      <td>02 12, 2014</td>\n",
       "      <td>1392163200</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A1POFVVXUZR3IQ</td>\n",
       "      <td>Z Hayes</td>\n",
       "      <td>Difficult to get into, but has its moments</td>\n",
       "      <td>Although I am a great fan of the Harry Potter ...</td>\n",
       "      <td>3</td>\n",
       "      <td>07 18, 2013</td>\n",
       "      <td>1374105600</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A1YSU2VSUJZAR5</td>\n",
       "      <td>zolteg59</td>\n",
       "      <td>The Casual Vacancy</td>\n",
       "      <td>While the story was intriguing, and I am a hug...</td>\n",
       "      <td>1</td>\n",
       "      <td>11 11, 2012</td>\n",
       "      <td>1352592000</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A2ZF888HX9YR8E</td>\n",
       "      <td>Zoobeefoo</td>\n",
       "      <td>A better read for Brits perhaps?</td>\n",
       "      <td>What an odd book!  The adolescent characters a...</td>\n",
       "      <td>3</td>\n",
       "      <td>12 30, 2012</td>\n",
       "      <td>1356825600</td>\n",
       "      <td>[2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A3VE36BNPVYR4N</td>\n",
       "      <td>zoshi</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>Chatty and immediately comfortable to read. It...</td>\n",
       "      <td>5</td>\n",
       "      <td>10 16, 2012</td>\n",
       "      <td>1350345600</td>\n",
       "      <td>[2, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2050 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           asin     reviewer_id       reviewer_name  \\\n",
       "0     316228532   AY2UIGHCB4VPB                 NaN   \n",
       "1     316228532  A2L17U0TWH9UWS                1075   \n",
       "2     316228532  A2R63TBVG5OAF6               12121   \n",
       "3     316228532   ACU39L9G696US             123esmo   \n",
       "4     316228532  A3N7KY1PBMF880  &#34;Bad Cat!&#34;   \n",
       "...         ...             ...                 ...   \n",
       "2045  316228532  A1SCYWLS37YR50                  ZC   \n",
       "2046  316228532  A1POFVVXUZR3IQ             Z Hayes   \n",
       "2047  316228532  A1YSU2VSUJZAR5            zolteg59   \n",
       "2048  316228532  A2ZF888HX9YR8E           Zoobeefoo   \n",
       "2049  316228532  A3VE36BNPVYR4N               zoshi   \n",
       "\n",
       "                                         summary  \\\n",
       "0                               but a good read!   \n",
       "1                             Not worth the time   \n",
       "2                             The Casual Vacancy   \n",
       "3               Expecting more from J.K. Rowling   \n",
       "4                       Sorry That I  Bought It.   \n",
       "...                                          ...   \n",
       "2045       Spectacular prose in a rambling story   \n",
       "2046  Difficult to get into, but has its moments   \n",
       "2047                          The Casual Vacancy   \n",
       "2048            A better read for Brits perhaps?   \n",
       "2049                                   Loved it!   \n",
       "\n",
       "                                            review_text  overall  review_time  \\\n",
       "0                 A departure for her, but a good read!        5  07 12, 2014   \n",
       "1     I had a hard time remembering who each charact...        2  11 12, 2013   \n",
       "2     This is the only review I have ever written.  ...        1   10 1, 2012   \n",
       "3     I was expecting more from J.K. Rowling, it's a...        2  01 10, 2013   \n",
       "4     As big a fan as I am of J K Rowling's Harry Po...        1  05 11, 2013   \n",
       "...                                                 ...      ...          ...   \n",
       "2045  Spectacular prose in a rambling story that see...        5  02 12, 2014   \n",
       "2046  Although I am a great fan of the Harry Potter ...        3  07 18, 2013   \n",
       "2047  While the story was intriguing, and I am a hug...        1  11 11, 2012   \n",
       "2048  What an odd book!  The adolescent characters a...        3  12 30, 2012   \n",
       "2049  Chatty and immediately comfortable to read. It...        5  10 16, 2012   \n",
       "\n",
       "      unix_review_time   helpful  \n",
       "0           1405123200    [0, 0]  \n",
       "1           1384214400    [0, 1]  \n",
       "2           1349049600  [13, 25]  \n",
       "3           1357776000    [0, 1]  \n",
       "4           1368230400    [0, 3]  \n",
       "...                ...       ...  \n",
       "2045        1392163200    [1, 1]  \n",
       "2046        1374105600    [1, 1]  \n",
       "2047        1352592000    [0, 1]  \n",
       "2048        1356825600    [2, 3]  \n",
       "2049        1350345600    [2, 3]  \n",
       "\n",
       "[2050 rows x 9 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(['asin', 'reviewer_id', 'reviewer_name', 'summary', 'review_time', 'unix_review_time', 'helpful'],\n",
    "    axis = 1,\n",
    "    inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A departure for her, but a good read!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I had a hard time remembering who each charact...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is the only review I have ever written.  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was expecting more from J.K. Rowling, it's a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As big a fan as I am of J K Rowling's Harry Po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>Spectacular prose in a rambling story that see...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>Although I am a great fan of the Harry Potter ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>While the story was intriguing, and I am a hug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>What an odd book!  The adolescent characters a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>Chatty and immediately comfortable to read. It...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2050 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_text  overall\n",
       "0                 A departure for her, but a good read!        5\n",
       "1     I had a hard time remembering who each charact...        2\n",
       "2     This is the only review I have ever written.  ...        1\n",
       "3     I was expecting more from J.K. Rowling, it's a...        2\n",
       "4     As big a fan as I am of J K Rowling's Harry Po...        1\n",
       "...                                                 ...      ...\n",
       "2045  Spectacular prose in a rambling story that see...        5\n",
       "2046  Although I am a great fan of the Harry Potter ...        3\n",
       "2047  While the story was intriguing, and I am a hug...        1\n",
       "2048  What an odd book!  The adolescent characters a...        3\n",
       "2049  Chatty and immediately comfortable to read. It...        5\n",
       "\n",
       "[2050 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    464\n",
       "5    457\n",
       "3    397\n",
       "2    373\n",
       "1    359\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.overall.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_text    0\n",
       "overall        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = df.review_text\n",
    "c = df.overall.map({1:-1, 2:-1, 3:0, 4:1, 5:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_c, test_c = cross_validation.train_test_split(X, c, train_size = .6, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TF-IDF and `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.TfidfVectorizer(stop_words = 'english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "TfidfVectorizer - Vocabulary wasn't fitted.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-1b61b1dca25c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/ga/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mget_feature_names\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    901\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_feature_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0;34m\"\"\"Array mapping from feature integer indices to feature name\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_vocabulary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         return [t for t, i in sorted(six.iteritems(self.vocabulary_),\n",
      "\u001b[0;32m/Users/ga/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_check_vocabulary\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;34m\"\"\"Check if vocabulary is empty or missing (not fit-ed)\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"%(name)s - Vocabulary wasn't fitted.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vocabulary_'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/ga/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[0;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[1;32m    676\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    677\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall_or_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mattr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mattributes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 678\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFittedError\u001b[0m: TfidfVectorizer - Vocabulary wasn't fitted."
     ]
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer=u'word', binary=False, decode_error=u'strict',\n",
       "        dtype=<type 'numpy.int64'>, encoding=u'utf-8', input=u'content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=3,\n",
       "        ngram_range=(1, 3), norm=u'l2', preprocessor=None, smooth_idf=True,\n",
       "        stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "        token_pattern=u'(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=<__main__.CustomTokenizer object at 0x1192ecd90>,\n",
       "        use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1',\n",
       " u'1 star',\n",
       " u'10',\n",
       " u'100',\n",
       " u'100 page',\n",
       " u'12',\n",
       " u'12 star',\n",
       " u'13',\n",
       " u'14',\n",
       " u'15',\n",
       " u'150',\n",
       " u'150 page',\n",
       " u'16',\n",
       " u'1799',\n",
       " u'18',\n",
       " u'1984',\n",
       " u'19th',\n",
       " u'1star',\n",
       " u'1star review',\n",
       " u'2',\n",
       " u'2 star',\n",
       " u'20',\n",
       " u'200',\n",
       " u'200 page',\n",
       " u'2012',\n",
       " u'23',\n",
       " u'25',\n",
       " u'3',\n",
       " u'3 star',\n",
       " u'30',\n",
       " u'300',\n",
       " u'300 page',\n",
       " u'34',\n",
       " u'34 34',\n",
       " u'34 adult',\n",
       " u'34 adult 34',\n",
       " u'34 bad',\n",
       " u'34 book',\n",
       " u'34 casual',\n",
       " u'34 casual vacanc',\n",
       " u'34 charact',\n",
       " u'34 enjoy',\n",
       " u'34 f',\n",
       " u'34 f 34',\n",
       " u'34 get',\n",
       " u'34 good',\n",
       " u'34 harri',\n",
       " u'34 harri potter',\n",
       " u'34 novel',\n",
       " u'34 plot',\n",
       " u'34 real',\n",
       " u'34 town',\n",
       " u'34 word',\n",
       " u'35',\n",
       " u'35 star',\n",
       " u'3rd',\n",
       " u'4',\n",
       " u'4 5',\n",
       " u'4 5 star',\n",
       " u'4 letter',\n",
       " u'4 letter word',\n",
       " u'4 star',\n",
       " u'40',\n",
       " u'400',\n",
       " u'400 page',\n",
       " u'45',\n",
       " u'5',\n",
       " u'5 star',\n",
       " u'50',\n",
       " u'50 page',\n",
       " u'500',\n",
       " u'500 page',\n",
       " u'503',\n",
       " u'503 page',\n",
       " u'512',\n",
       " u'6',\n",
       " u'60',\n",
       " u'7',\n",
       " u'70',\n",
       " u'8',\n",
       " u'80',\n",
       " u'8211',\n",
       " u'8217',\n",
       " u'8217 one',\n",
       " u'8217 read',\n",
       " u'8220',\n",
       " u'8221',\n",
       " u'abandon',\n",
       " u'abbey',\n",
       " u'abil',\n",
       " u'abil creat',\n",
       " u'abil weav',\n",
       " u'abject',\n",
       " u'abl',\n",
       " u'abl get',\n",
       " u'abl put',\n",
       " u'abrupt',\n",
       " u'abruptli',\n",
       " u'absolut',\n",
       " u'absolut love',\n",
       " u'absorb',\n",
       " u'abund',\n",
       " u'abus',\n",
       " u'abus drug',\n",
       " u'accent',\n",
       " u'accept',\n",
       " u'access',\n",
       " u'accomplish',\n",
       " u'account',\n",
       " u'accur',\n",
       " u'accus',\n",
       " u'achiev',\n",
       " u'acknowledg',\n",
       " u'acquaint',\n",
       " u'across',\n",
       " u'act',\n",
       " u'act like',\n",
       " u'action',\n",
       " u'action book',\n",
       " u'activ',\n",
       " u'actor',\n",
       " u'actual',\n",
       " u'actual care',\n",
       " u'actual found',\n",
       " u'actual like',\n",
       " u'actual plot',\n",
       " u'actual read',\n",
       " u'actual write',\n",
       " u'acut',\n",
       " u'ad',\n",
       " u'adapt',\n",
       " u'add',\n",
       " u'add anyth',\n",
       " u'addict',\n",
       " u'addict clinic',\n",
       " u'addict mother',\n",
       " u'addict terri',\n",
       " u'addit',\n",
       " u'address',\n",
       " u'adject',\n",
       " u'adjust',\n",
       " u'administr',\n",
       " u'admir',\n",
       " u'admir j',\n",
       " u'admir j k',\n",
       " u'admir jk',\n",
       " u'admit',\n",
       " u'admit nt',\n",
       " u'adolesc',\n",
       " u'adopt',\n",
       " u'ador',\n",
       " u'adult',\n",
       " u'adult 34',\n",
       " u'adult audienc',\n",
       " u'adult book',\n",
       " u'adult book disappoint',\n",
       " u'adult book like',\n",
       " u'adult book would',\n",
       " u'adult charact',\n",
       " u'adult children',\n",
       " u'adult content',\n",
       " u'adult fiction',\n",
       " u'adult get',\n",
       " u'adult harri',\n",
       " u'adult harri potter',\n",
       " u'adult issu',\n",
       " u'adult languag',\n",
       " u'adult love',\n",
       " u'adult market',\n",
       " u'adult novel',\n",
       " u'adult novel jk',\n",
       " u'adult nt',\n",
       " u'adult read',\n",
       " u'adult rowl',\n",
       " u'adult sex',\n",
       " u'adult situat',\n",
       " u'adult stori',\n",
       " u'adult theme',\n",
       " u'adult well',\n",
       " u'adult would',\n",
       " u'adulteri',\n",
       " u'adultsi',\n",
       " u'advantag',\n",
       " u'adventur',\n",
       " u'advertis',\n",
       " u'advic',\n",
       " u'advoc',\n",
       " u'affair',\n",
       " u'affect',\n",
       " u'affect live',\n",
       " u'aforement',\n",
       " u'afraid',\n",
       " u'afternoon',\n",
       " u'agatha',\n",
       " u'agatha christi',\n",
       " u'age',\n",
       " u'agenda',\n",
       " u'aggress',\n",
       " u'ago',\n",
       " u'agre',\n",
       " u'ah',\n",
       " u'ahead',\n",
       " u'aim',\n",
       " u'air',\n",
       " u'airport',\n",
       " u'ala',\n",
       " u'albeit',\n",
       " u'alcohol',\n",
       " u'alert',\n",
       " u'alien',\n",
       " u'align',\n",
       " u'alik',\n",
       " u'aliv',\n",
       " u'allegi',\n",
       " u'allianc',\n",
       " u'allow',\n",
       " u'almost',\n",
       " u'almost everi',\n",
       " u'almost feel',\n",
       " u'almost gave',\n",
       " u'almost like',\n",
       " u'almost need',\n",
       " u'alon',\n",
       " u'along',\n",
       " u'along line',\n",
       " u'along nt',\n",
       " u'alot',\n",
       " u'alreadi',\n",
       " u'alreadi know',\n",
       " u'also',\n",
       " u'also enjoy',\n",
       " u'also found',\n",
       " u'also got',\n",
       " u'also love',\n",
       " u'also made',\n",
       " u'also nt',\n",
       " u'also read',\n",
       " u'also show',\n",
       " u'also stori',\n",
       " u'also thought',\n",
       " u'also want',\n",
       " u'altern',\n",
       " u'although',\n",
       " u'altogeth',\n",
       " u'alway',\n",
       " u'alway interest',\n",
       " u'alway like',\n",
       " u'alway nice',\n",
       " u'amaz',\n",
       " u'amaz stori',\n",
       " u'amaz writer',\n",
       " u'amazingli',\n",
       " u'amazon',\n",
       " u'amazon review',\n",
       " u'ambit',\n",
       " u'ambiti',\n",
       " u'america',\n",
       " u'american',\n",
       " u'american reader',\n",
       " u'amidst',\n",
       " u'among',\n",
       " u'among charact',\n",
       " u'amongst',\n",
       " u'amount',\n",
       " u'amount charact',\n",
       " u'amus',\n",
       " u'analysi',\n",
       " u'analyz',\n",
       " u'ancient',\n",
       " u'ancient abbey',\n",
       " u'andor',\n",
       " u'andrew',\n",
       " u'andrew stuart',\n",
       " u'aneur',\n",
       " u'aneurysm',\n",
       " u'angel',\n",
       " u'anger',\n",
       " u'angl',\n",
       " u'angri',\n",
       " u'angst',\n",
       " u'anniversari',\n",
       " u'announc',\n",
       " u'annoy',\n",
       " u'anoth',\n",
       " u'anoth adult',\n",
       " u'anoth author',\n",
       " u'anoth book',\n",
       " u'anoth charact',\n",
       " u'anoth good',\n",
       " u'anoth harri',\n",
       " u'anoth harri potter',\n",
       " u'anoth nt',\n",
       " u'anoth one',\n",
       " u'anoth tri',\n",
       " u'answer',\n",
       " u'antagonist',\n",
       " u'anticip',\n",
       " u'antithesi',\n",
       " u'anxiou',\n",
       " u'anymor',\n",
       " u'anyon',\n",
       " u'anyon els',\n",
       " u'anyon like',\n",
       " u'anyon read',\n",
       " u'anyth',\n",
       " u'anyth els',\n",
       " u'anyth like',\n",
       " u'anyth like harri',\n",
       " u'anyth read',\n",
       " u'anyth stori',\n",
       " u'anyth write',\n",
       " u'anyway',\n",
       " u'anywher',\n",
       " u'apart',\n",
       " u'appal',\n",
       " u'appar',\n",
       " u'appeal',\n",
       " u'appeal reader',\n",
       " u'appear',\n",
       " u'appl',\n",
       " u'appl orang',\n",
       " u'applaud',\n",
       " u'appli',\n",
       " u'appreci',\n",
       " u'approach',\n",
       " u'appropri',\n",
       " u'approxim',\n",
       " u'apt',\n",
       " u'area',\n",
       " u'arf',\n",
       " u'argu',\n",
       " u'argument',\n",
       " u'aris',\n",
       " u'around',\n",
       " u'around us',\n",
       " u'array',\n",
       " u'array charact',\n",
       " u'arrog',\n",
       " u'art',\n",
       " u'artist',\n",
       " u'asid',\n",
       " u'ask',\n",
       " u'asleep',\n",
       " u'aspect',\n",
       " u'assembl',\n",
       " u'assign',\n",
       " u'assist',\n",
       " u'assum',\n",
       " u'assumpt',\n",
       " u'astound',\n",
       " u'astut',\n",
       " u'astut observ',\n",
       " u'atmospher',\n",
       " u'attach',\n",
       " u'attack',\n",
       " u'attempt',\n",
       " u'attempt read',\n",
       " u'attend',\n",
       " u'attent',\n",
       " u'attitud',\n",
       " u'attract',\n",
       " u'audienc',\n",
       " u'audio',\n",
       " u'audio version',\n",
       " u'audiobook',\n",
       " u'austen',\n",
       " u'authent',\n",
       " u'author',\n",
       " u'author book',\n",
       " u'author complet',\n",
       " u'author creat',\n",
       " u'author expect',\n",
       " u'author great',\n",
       " u'author harri',\n",
       " u'author harri potter',\n",
       " u'author jk',\n",
       " u'author jk rowl',\n",
       " u'author must',\n",
       " u'author new',\n",
       " u'author new book',\n",
       " u'author read',\n",
       " u'author realli',\n",
       " u'author seem',\n",
       " u'author skill',\n",
       " u'author take',\n",
       " u'author talent',\n",
       " u'author tri',\n",
       " u'author want',\n",
       " u'author work',\n",
       " u'author would',\n",
       " u'author write',\n",
       " u'author written',\n",
       " u'author wrote',\n",
       " u'avail',\n",
       " u'averag',\n",
       " u'avid',\n",
       " u'avid harri',\n",
       " u'avid harri potter',\n",
       " u'avoid',\n",
       " u'aw',\n",
       " u'await',\n",
       " u'awar',\n",
       " u'away',\n",
       " u'awe',\n",
       " u'awesom',\n",
       " u'awhil',\n",
       " u'awhil get',\n",
       " u'awhil get book',\n",
       " u'awkward',\n",
       " u'b',\n",
       " u'babi',\n",
       " u'back',\n",
       " u'back book',\n",
       " u'back check',\n",
       " u'back children',\n",
       " u'back finish',\n",
       " u'back forth',\n",
       " u'back harri',\n",
       " u'back read',\n",
       " u'back reread',\n",
       " u'back stori',\n",
       " u'back world',\n",
       " u'background',\n",
       " u'backstab',\n",
       " u'backstori',\n",
       " u'bad',\n",
       " u'bad book',\n",
       " u'bad decis',\n",
       " u'bad guy',\n",
       " u'bad languag',\n",
       " u'bad thing',\n",
       " u'badli',\n",
       " u'badli written',\n",
       " u'bag',\n",
       " u'balanc',\n",
       " u'ball',\n",
       " u'banal',\n",
       " u'band',\n",
       " u'bare',\n",
       " u'barri',\n",
       " u'barri death',\n",
       " u'barri fairbroth',\n",
       " u'barri fairbroth death',\n",
       " u'barri fairbroth die',\n",
       " u'barri fairbroth drop',\n",
       " u'barri fairweath',\n",
       " u'base',\n",
       " u'basi',\n",
       " u'basic',\n",
       " u'battl',\n",
       " u'bbc',\n",
       " u'be',\n",
       " u'beach',\n",
       " u'bear',\n",
       " u'beat',\n",
       " u'beauti',\n",
       " u'beauti descript',\n",
       " u'beauti write',\n",
       " u'beauti written',\n",
       " u'becam',\n",
       " u'becom',\n",
       " u'becom clear',\n",
       " u'began',\n",
       " u'begin',\n",
       " u'begin book',\n",
       " u'begin end',\n",
       " u'begin like',\n",
       " u'begin middl',\n",
       " u'begin middl end',\n",
       " u'begin novel',\n",
       " u'behav',\n",
       " u'behavior',\n",
       " u'behind',\n",
       " u'behind close',\n",
       " u'behind close door',\n",
       " u'belief',\n",
       " u'believ',\n",
       " u'believ charact',\n",
       " u'believ person',\n",
       " u'believ stori',\n",
       " u'believ would',\n",
       " u'bellchapel',\n",
       " u'belov',\n",
       " u'beneath',\n",
       " u'benefit',\n",
       " u'besid',\n",
       " u'best',\n",
       " u'best seller',\n",
       " u'best think',\n",
       " u'bestsel',\n",
       " u'betray',\n",
       " u'better',\n",
       " u'better book',\n",
       " u'better harri',\n",
       " u'better life',\n",
       " u'better stori',\n",
       " u'better word',\n",
       " u'beyond',\n",
       " u'bias',\n",
       " u'bibl',\n",
       " u'big',\n",
       " u'big fan',\n",
       " u'big fan harri',\n",
       " u'big harri',\n",
       " u'big harri potter',\n",
       " u'bigger',\n",
       " u'biggest',\n",
       " u'bigotri',\n",
       " u'binchi',\n",
       " u'bit',\n",
       " u'bit depress',\n",
       " u'bit disappoint',\n",
       " u'bit hard',\n",
       " u'bit much',\n",
       " u'bit rowl',\n",
       " u'bit slow',\n",
       " u'bit time',\n",
       " u'bite',\n",
       " u'bitter',\n",
       " u'bitter end',\n",
       " u'black',\n",
       " u'black comedi',\n",
       " u'black white',\n",
       " u'bland',\n",
       " u'bleak',\n",
       " u'bleak book',\n",
       " u'bleaker',\n",
       " u'blend',\n",
       " u'blight',\n",
       " u'blockbust',\n",
       " u'blog',\n",
       " u'blood',\n",
       " u'blown',\n",
       " u'blown away',\n",
       " u'board',\n",
       " u'board school',\n",
       " u'bodi',\n",
       " u'bog',\n",
       " u'bog mani',\n",
       " u'bog mani charact',\n",
       " u'bold',\n",
       " u'bomb',\n",
       " u'book',\n",
       " u'book 1',\n",
       " u'book 34',\n",
       " u'book 500',\n",
       " u'book 500 page',\n",
       " u'book 8217',\n",
       " u'book 8217 read',\n",
       " u'book absolut',\n",
       " u'book actual',\n",
       " u'book adult',\n",
       " u'book adult book',\n",
       " u'book almost',\n",
       " u'book also',\n",
       " u'book although',\n",
       " u'book alway',\n",
       " u'book amaz',\n",
       " u'book anyon',\n",
       " u'book anyth',\n",
       " u'book anyth like',\n",
       " u'book attempt',\n",
       " u'book author',\n",
       " u'book aw',\n",
       " u'book bad',\n",
       " u'book barri',\n",
       " u'book base',\n",
       " u'book becom',\n",
       " u'book begin',\n",
       " u'book better',\n",
       " u'book bit',\n",
       " u'book book',\n",
       " u'book bore',\n",
       " u'book bought',\n",
       " u'book ca',\n",
       " u'book ca nt',\n",
       " u'book came',\n",
       " u'book care',\n",
       " u'book casual',\n",
       " u'book casual vacanc',\n",
       " u'book certainli',\n",
       " u'book charact',\n",
       " u'book charact book',\n",
       " u'book children',\n",
       " u'book club',\n",
       " u'book club select',\n",
       " u'book come',\n",
       " u'book complet',\n",
       " u'book contain',\n",
       " u'book could',\n",
       " u'book could nt',\n",
       " u'book curiou',\n",
       " u'book dark',\n",
       " u'book day',\n",
       " u'book deal',\n",
       " u'book death',\n",
       " u'book definit',\n",
       " u'book depress',\n",
       " u'book deserv',\n",
       " u'book differ',\n",
       " u'book difficult',\n",
       " u'book disappoint',\n",
       " u'book done',\n",
       " u'book easi',\n",
       " u'book easi read',\n",
       " u'book end',\n",
       " u'book enjoy',\n",
       " u'book entertain',\n",
       " u'book even',\n",
       " u'book even though',\n",
       " u'book ever',\n",
       " u'book ever read',\n",
       " u'book everyon',\n",
       " u'book excel',\n",
       " u'book excit',\n",
       " u'book expect',\n",
       " u'book expect harri',\n",
       " u'book extrem',\n",
       " u'book fact',\n",
       " u'book fan',\n",
       " u'book far',\n",
       " u'book fascin',\n",
       " u'book feel',\n",
       " u'book feel like',\n",
       " u'book felt',\n",
       " u'book felt like',\n",
       " u'book fill',\n",
       " u'book find',\n",
       " u'book finish',\n",
       " u'book first',\n",
       " u'book follow',\n",
       " u'book found',\n",
       " u'book four',\n",
       " u'book friend',\n",
       " u'book full',\n",
       " u'book funni',\n",
       " u'book futur',\n",
       " u'book gave',\n",
       " u'book get',\n",
       " u'book gift',\n",
       " u'book give',\n",
       " u'book glad',\n",
       " u'book go',\n",
       " u'book go differ',\n",
       " u'book good',\n",
       " u'book got',\n",
       " u'book great',\n",
       " u'book gritti',\n",
       " u'book guess',\n",
       " u'book happen',\n",
       " u'book happi',\n",
       " u'book hard',\n",
       " u'book hard get',\n",
       " u'book hard read',\n",
       " u'book harri',\n",
       " u'book harri potter',\n",
       " u'book heavi',\n",
       " u'book high',\n",
       " u'book hit',\n",
       " u'book hope',\n",
       " u'book horribl',\n",
       " u'book howev',\n",
       " u'book hp',\n",
       " u'book huge',\n",
       " u'book impress',\n",
       " u'book includ',\n",
       " u'book instead',\n",
       " u'book interest',\n",
       " u'book intrigu',\n",
       " u'book jk',\n",
       " u'book jk rowl',\n",
       " u'book jkr',\n",
       " u'book keep',\n",
       " u'book kept',\n",
       " u'book kid',\n",
       " u'book kind',\n",
       " u'book kindl',\n",
       " u'book knew',\n",
       " u'book know',\n",
       " u'book languag',\n",
       " u'book last',\n",
       " u'book learn',\n",
       " u'book least',\n",
       " u'book leav',\n",
       " u'book left',\n",
       " u'book less',\n",
       " u'book let',\n",
       " u'book librari',\n",
       " u'book like',\n",
       " u'book like book',\n",
       " u'book like charact',\n",
       " u'book littl',\n",
       " u'book long',\n",
       " u'book look',\n",
       " u'book look forward',\n",
       " u'book lot',\n",
       " u'book lot charact',\n",
       " u'book love',\n",
       " u'book made',\n",
       " u'book main',\n",
       " u'book main charact',\n",
       " u'book make',\n",
       " u'book mani',\n",
       " u'book mani charact',\n",
       " u'book may',\n",
       " u'book mayb',\n",
       " u'book mean',\n",
       " u'book mention',\n",
       " u'book merit',\n",
       " u'book might',\n",
       " u'book mostli',\n",
       " u'book much',\n",
       " u'book need',\n",
       " u'book neg',\n",
       " u'book never',\n",
       " u'book noth',\n",
       " u'book noth like',\n",
       " u'book nt',\n",
       " u'book nt even',\n",
       " u'book nt expect',\n",
       " u'book nt like',\n",
       " u'book nt read',\n",
       " u'book nt want',\n",
       " u'book often',\n",
       " u'book okay',\n",
       " u'book one',\n",
       " u'book open',\n",
       " u'book overal',\n",
       " u'book page',\n",
       " u'book pain',\n",
       " u'book peopl',\n",
       " u'book perfect',\n",
       " u'book plot',\n",
       " u'book polar',\n",
       " u'book polit',\n",
       " u'book possibl',\n",
       " u'book pretti',\n",
       " u'book probabl',\n",
       " u'book problem',\n",
       " u'book put',\n",
       " u'book quit',\n",
       " u'book rate',\n",
       " u'book read',\n",
       " u'book read like',\n",
       " u'book reader',\n",
       " u'book realli',\n",
       " u'book realli nt',\n",
       " u'book reason',\n",
       " u'book receiv',\n",
       " u'book recommend',\n",
       " u'book redeem',\n",
       " u'book rememb',\n",
       " u'book remind',\n",
       " u'book review',\n",
       " u'book right',\n",
       " u'book rowl',\n",
       " u'book sad',\n",
       " u'book said',\n",
       " u'book say',\n",
       " u'book see',\n",
       " u'book seem',\n",
       " u'book seen',\n",
       " u'book seen movi',\n",
       " u'book seri',\n",
       " u'book set',\n",
       " u'book sever',\n",
       " u'book show',\n",
       " u'book simpli',\n",
       " u'book sinc',\n",
       " u'book slow',\n",
       " u'book slow start',\n",
       " u'book small',\n",
       " u'book small town',\n",
       " u'book someon',\n",
       " u'book sorri',\n",
       " u'book start',\n",
       " u'book start slow',\n",
       " u'book still',\n",
       " u'book stori',\n",
       " u'book strength',\n",
       " u'book struggl',\n",
       " u'book sure',\n",
       " u'book surpris',\n",
       " u'book take',\n",
       " u'book take long',\n",
       " u'book taken',\n",
       " u'book teenag',\n",
       " u'book tell',\n",
       " u'book think',\n",
       " u'book thoroughli',\n",
       " u'book though',\n",
       " u'book thought',\n",
       " u'book thought would',\n",
       " u'book three',\n",
       " u'book time',\n",
       " u'book told',\n",
       " u'book took',\n",
       " u'book total',\n",
       " u'book tri',\n",
       " u'book truli',\n",
       " u'book two',\n",
       " u'book uplift',\n",
       " u'book wait',\n",
       " u'book want',\n",
       " u'book wast',\n",
       " u'book way',\n",
       " u'book well',\n",
       " u'book well written',\n",
       " u'book went',\n",
       " u'book without',\n",
       " u'book wonder',\n",
       " u'book work',\n",
       " u'book worth',\n",
       " u'book would',\n",
       " u'book write',\n",
       " u'book written',\n",
       " u'book written adult',\n",
       " u'book written author',\n",
       " u'book written jk',\n",
       " u'book ye',\n",
       " u'book young',\n",
       " u'booki',\n",
       " u'bookit',\n",
       " u'bookstor',\n",
       " u'bookth',\n",
       " u'bookth book',\n",
       " u'border',\n",
       " u'bore',\n",
       " u'bore book',\n",
       " u'bore bore',\n",
       " u'bore bore bore',\n",
       " u'bore could',\n",
       " u'bore nt',\n",
       " u'bore read',\n",
       " u'bore stori',\n",
       " u'bore uninterest',\n",
       " u'borrow',\n",
       " u'bother',\n",
       " u'bother read',\n",
       " u'bottom',\n",
       " u'bought',\n",
       " u'bought book',\n",
       " u'bound',\n",
       " u'bow',\n",
       " u'boy',\n",
       " u'boy band',\n",
       " u'brain',\n",
       " u'branch',\n",
       " u'brave',\n",
       " u'bravo',\n",
       " u'breadth',\n",
       " u'break',\n",
       " u'brief',\n",
       " u'bright',\n",
       " u'brillianc',\n",
       " u'brilliant',\n",
       " u'brilliant writer',\n",
       " u'brilliantli',\n",
       " u'brilliantli written',\n",
       " u'bring',\n",
       " u'bring stori',\n",
       " u'bring togeth',\n",
       " u'bring us',\n",
       " u'bring worst',\n",
       " u'brit',\n",
       " u'britain',\n",
       " u'british',\n",
       " u'british life',\n",
       " u'british slang',\n",
       " u'british town',\n",
       " u'british villag',\n",
       " u'broad',\n",
       " u'broke',\n",
       " u'broken',\n",
       " u'brother',\n",
       " u'brought',\n",
       " u'brown',\n",
       " u'brutal',\n",
       " u'build',\n",
       " u'built',\n",
       " u'bulli',\n",
       " u'bunch',\n",
       " u'burden',\n",
       " u'busi',\n",
       " u'buy',\n",
       " u'buy book',\n",
       " u'c',\n",
       " u'ca',\n",
       " u'ca nt',\n",
       " u'ca nt believ',\n",
       " u'ca nt compar',\n",
       " u'ca nt even',\n",
       " u'ca nt get',\n",
       " u'ca nt help',\n",
       " u'ca nt imagin',\n",
       " u'ca nt put',\n",
       " u'ca nt say',\n",
       " u'ca nt wait',\n",
       " u'call',\n",
       " u'call field',\n",
       " u'call pagford',\n",
       " u'came',\n",
       " u'came finish',\n",
       " u'came togeth',\n",
       " u'camp',\n",
       " u'campaign',\n",
       " u'candid',\n",
       " u'capabl',\n",
       " u'capabl creat',\n",
       " u'captiv',\n",
       " u'captur',\n",
       " u'captur way',\n",
       " u'car',\n",
       " u'cardboard',\n",
       " u'cardboard cutout',\n",
       " u'care',\n",
       " u'care book',\n",
       " u'care charact',\n",
       " u'care enough',\n",
       " u'care happen',\n",
       " u'care much',\n",
       " u'care stori',\n",
       " u'career',\n",
       " u'caricatur',\n",
       " u'carri',\n",
       " u'case',\n",
       " u'cast',\n",
       " u'cast charact',\n",
       " u'casual',\n",
       " u'casual vacanc',\n",
       " u'casual vacanc 34',\n",
       " u'casual vacanc charact',\n",
       " u'casual vacanc could',\n",
       " u'casual vacanc far',\n",
       " u'casual vacanc feel',\n",
       " u'casual vacanc good',\n",
       " u'casual vacanc harri',\n",
       " u'casual vacanc jk',\n",
       " u'casual vacanc like',\n",
       " u'casual vacanc love',\n",
       " u'casual vacanc nt',\n",
       " u'casual vacanc parish',\n",
       " u'casual vacanc realli',\n",
       " u'casual vacanc rowl',\n",
       " u'casual vacanc show',\n",
       " u'casual vacanc think',\n",
       " u'casual vacanc took',\n",
       " u'catalyst',\n",
       " u'catastroph',\n",
       " u'catcher',\n",
       " u'catcher rye',\n",
       " u'categori',\n",
       " u'caught',\n",
       " u'caus',\n",
       " u'cd',\n",
       " u'celebr',\n",
       " u'cent',\n",
       " u'center',\n",
       " u'center around',\n",
       " u'centr',\n",
       " u'central',\n",
       " u'central charact',\n",
       " u'centuri',\n",
       " u'certain',\n",
       " u'certain charact',\n",
       " u'certainli',\n",
       " u'certainli good',\n",
       " u'chain',\n",
       " u'chain reaction',\n",
       " u'challeng',\n",
       " u'champion',\n",
       " u'chanc',\n",
       " u'chang',\n",
       " u'chang genr',\n",
       " u'chang live',\n",
       " u'chao',\n",
       " u'chapter',\n",
       " u'chapter one',\n",
       " u'chapter read',\n",
       " u'charact',\n",
       " u'charact 34',\n",
       " u'charact 8217',\n",
       " u'charact almost',\n",
       " u'charact also',\n",
       " u'charact anoth',\n",
       " u'charact author',\n",
       " u'charact becom',\n",
       " u'charact begin',\n",
       " u'charact believ',\n",
       " u'charact better',\n",
       " u'charact bit',\n",
       " u'charact book',\n",
       " u'charact book nt',\n",
       " u'charact care',\n",
       " u'charact care book',\n",
       " u'charact casual',\n",
       " u'charact casual vacanc',\n",
       " u'charact charact',\n",
       " u'charact complet',\n",
       " u'charact complex',\n",
       " ...]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the feature matrix `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_X = vectorizer.transform(train_X)\n",
    "test_X = vectorizer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1230x6272 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 79917 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.06615307],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.23061146, ...,  0.        ,\n",
       "          0.        ,  0.        ]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = linear_model.LogisticRegression().\\\n",
    "    fit(train_X, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ensemble.RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.80894308943089432"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_X, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.67479799751585789"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation.cross_val_score(model, train_X, train_c,cv = 5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    548\n",
       "-1    438\n",
       " 0    244\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_c.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.698780487804878"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_X, test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_c_hat = cross_validation.cross_val_predict(model, train_X, train_c,cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64552845528455283"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(train_c,train_c_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True</th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>305</td>\n",
       "      <td>99</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132</td>\n",
       "      <td>141</td>\n",
       "      <td>485</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "True        -1    0    1\n",
       "Predicted               \n",
       "-1         305   99   62\n",
       " 0           1    4    1\n",
       " 1         132  141  485"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train_c_hat, train_c, rownames = ['Predicted'], colnames = ['True'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.TfidfVectorizer(stop_words = 'english')\n",
    "\n",
    "class CustomTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.stemmer = stem.porter.PorterStemmer()\n",
    "\n",
    "    def __call__(self, document):\n",
    "        tokens = tokenize_text(document)\n",
    "        tokens = Stemmer.stem_tokens(tokens)\n",
    "        return tokens\n",
    "    \n",
    "vectorizer = feature_extraction.text.TfidfVectorizer(tokenizer = CustomTokenizer(), ngram_range = (1, 3), min_df = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # TODO..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
